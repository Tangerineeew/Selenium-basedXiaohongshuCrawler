{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入包(PypI)\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.http import TextResponse\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 启动 Chrome 浏览器实例：\n",
    "\n",
    "打开 **cmd** 命令提示符<输入以下命令（将 `your Chrome.exe path` 替换为您的 Chrome 浏览器路径）：\n",
    "```bash\n",
    "& \"your Chrome.exe path\" --remote-debugging-port=9222 --user-data-dir=\"C:\\selenum\\AutomationProfile\"\n",
    "```\n",
    "\n",
    "- 请将your Chrome.exe path替换为您的Chrome浏览器所在路径，例如<br>`C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe`\n",
    "- 配置 chromedriver 相关信息，请参考官方文档：[ChromeDriver](https://developer.chrome.com/docs/chromedriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置Chrome浏览器\n",
    "service = Service(\"C:\\\\Program Files\\\\Google\\\\Chrome\\\\Application\\\\chromedriver.exe\")\n",
    "\n",
    "options = Options()\n",
    "options.add_experimental_option('debuggerAddress', '127.0.0.1:9222')# 远程调控模式启用\n",
    "options.add_argument('--incognito')# 隐身/无痕模式启用\n",
    "browser = webdriver.Chrome(service=service, options=options)\n",
    "action = ActionChains(browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义全局变量\n",
    "key_word = \"\"\n",
    "num = 0\n",
    "\n",
    "def selenium_test():\n",
    "    global key_word, num# 使用全局变量\n",
    "    browser.get('https://www.xiaohongshu.com/explore')\n",
    "\n",
    "    print(\"即将开始检查小红书登录状态...\")\n",
    "    print(\"爬取数据有账户封禁的风险，建议使用非主账号登录。\")\n",
    "    # 检查是否成功登录小红书\n",
    "    while True:\n",
    "        page_source = browser.page_source\n",
    "        if '登录探索更多内容' in page_source:\n",
    "            time.sleep(10)\n",
    "            print('暂未登录，请手动登录')\n",
    "            print('检查时间:',time.ctime())\n",
    "            continue\n",
    "        else:\n",
    "            print('登录成功')\n",
    "            print('检查时间:',time.ctime())\n",
    "            time.sleep(3)\n",
    "            break\n",
    "\n",
    "    print(\"即将开始检查网页加载状态...\")\n",
    "    print(\"如果网页进入人机验证页面，请先手动完成验证。\")\n",
    "    print(\"请在文本框中根据提示输入搜索关键词和笔记爬取数量。\")\n",
    "    key_word = input(\"搜索关键词：\")\n",
    "    num = input(\"笔记爬取数量：\")\n",
    "    num = int(num)\n",
    "\n",
    "    url = f'https://www.xiaohongshu.com/search_result?keyword={key_word}&source=web_explore_feed'\n",
    "    browser.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    # 检查页面是否加载成功\n",
    "    while True:\n",
    "        if key_word in browser.title:\n",
    "            print('加载成功')\n",
    "            print('检查时间:',time.ctime())\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(2)\n",
    "\n",
    "selenium_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过模拟点击更改模式\n",
    "mode = browser.find_element(By.XPATH, '//*[@id=\"search-type\"]/div/div/div[2]')\n",
    "mode.click()# 模拟鼠标点击\n",
    "print('已自动更改模式为图文。')\n",
    "\n",
    "# 通过模拟点击更改排序方式\n",
    "sort_order = ['综合','最新','最热']\n",
    "print(\"请在文本框中根据提示输入对应数字来选择排序方式。\")\n",
    "for i, order in enumerate(sort_order, 1):\n",
    "    print(f'{i}.{order}')\n",
    "selected_order = input(\"请选择排序方式:\")\n",
    "\n",
    "try:\n",
    "    selected_order_index = int(selected_order)\n",
    "    selected_order_text = sort_order[selected_order_index-1]\n",
    "    element = browser.find_element(By.XPATH, '//*[@id=\"global\"]/div[2]/div[2]/div/div[1]/div[2]')\n",
    "    action.move_to_element(element).perform()# 模拟鼠标悬停\n",
    "    menu = browser.find_element(By.CLASS_NAME, 'dropdown-items')\n",
    "    option = menu.find_element(By.XPATH, f'/html/body/div[4]/div/li[{selected_order_index}]')\n",
    "    option.click()# 模拟鼠标点击\n",
    "    print('已选择排序方式为:',selected_order_text)\n",
    "    print('检查时间:',time.ctime())\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authorName_list = []\n",
    "likeNr_list = []\n",
    "URL_list = []\n",
    "userURL_list = []\n",
    "\n",
    "# 进度条: 实时跟踪已爬取的笔记数量\n",
    "qbar = tqdm(total=num)\n",
    "\n",
    "# 定义函数：解析网页内容，爬取数据\n",
    "def parsePage(key_word):\n",
    "    response = TextResponse(url=browser.current_url, body=key_word, encoding='utf-8')# 将key_word转换为Response对象\n",
    "    selector = Selector(response)\n",
    "    divs = selector.xpath('//div[contains(@class, \"feeds-container\")]/section/div')# 选中网页中包含笔记信息的部分\n",
    "\n",
    "    # 定义循环：遍历divs获取每一篇笔记的信息\n",
    "    for div in divs:\n",
    "        # 选择并提取网页数据\n",
    "        try:\n",
    "            author_name = div.xpath('./div/div/a/span/text()').extract_first()# 作者名字\n",
    "            like_nr = div.xpath('string(./div/div/span)').extract_first()# 获赞数量\n",
    "            url = div.xpath('./div/a/@href').extract_first().split('/')[-1]# 笔记URL\n",
    "            user_url = div.xpath('./div/div/a/@href').extract_first()# 用户URL\n",
    "\n",
    "            authorName_list.append(author_name)\n",
    "            likeNr_list.append(like_nr)\n",
    "            URL_list.append(url)\n",
    "            userURL_list.append(user_url)\n",
    "\n",
    "            time.sleep(0.35)\n",
    "\n",
    "            qbar.update(min(1, num - len(URL_list)))\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# 定义循环：检查是否已经爬取足够数量的笔记，或是否已经达到页面底部\n",
    "while len(URL_list) < num:\n",
    "    if '- THE END -' in browser.page_source:\n",
    "        print(f\"当前与{key_word}有关的笔记数量少于 {num}\")\n",
    "        print('检查时间:',time.ctime())\n",
    "        break\n",
    "    \n",
    "    parsePage(browser.page_source)# 解析当前页面\n",
    "    time.sleep(0.3)\n",
    "    browser.execute_script('window.scrollTo(0,document.body.scrollHeight)')# 模拟鼠标滚动\n",
    "    wait_time=random.uniform(3,5)# 生成随机等待时间\n",
    "    time.sleep(wait_time)\n",
    "\n",
    "if len(URL_list) > num:\n",
    "    URL_list = URL_list[:num]\n",
    "    authorName_list = authorName_list[:num]\n",
    "    likeNr_list = likeNr_list[:num]\n",
    "    userURL_list = userURL_list[:num]\n",
    "\n",
    "qbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(authorName_list) == len(likeNr_list) == len(URL_list) == len(userURL_list) == num):\n",
    "    print(\"所有属性列表长度均为\", num,\"，爬取成功！\")\n",
    "    print('检查时间:',time.ctime())\n",
    "else:\n",
    "    min_length = min(len(authorName_list), len(likeNr_list), len(URL_list), len(userURL_list))\n",
    "    print(\"当前属性列表长度最小值为\", min_length, \"请重新运行上一代码单元，直至所有属性列表长度均为\", num, \"！\")\n",
    "    print('检查时间:',time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据清洗\n",
    "likeNr_list_cleaned = []\n",
    "for like_nr in likeNr_list:\n",
    "    if 'w' in like_nr:\n",
    "        like_nr = like_nr.replace('w', '')\n",
    "        like_nr = float(like_nr) * 10000\n",
    "        like_nr = int(like_nr)\n",
    "    else:\n",
    "        like_nr = int(like_nr)\n",
    "    \n",
    "    likeNr_list_cleaned.append(like_nr)\n",
    "\n",
    "userURL_list_cleaned = [url.split('/')[-1] for url in userURL_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"以下为清洁数据示例：\")\n",
    "for i in range(3):\n",
    "    print(\"author_name:\", authorName_list[i])\n",
    "    print(\"like_nr:\", likeNr_list_cleaned[i])\n",
    "    print(\"url:\", URL_list[i])\n",
    "    print(\"user_url:\", userURL_list_cleaned[i])\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentNr_list = []\n",
    "content_list = []\n",
    "datePublished_list = []\n",
    "images_list = []\n",
    "starNr_list = []\n",
    "\n",
    "# 进度条: 实时跟踪已爬取的笔记数量\n",
    "qbar = tqdm(total=len(URL_list))\n",
    "\n",
    "# 定义循环：遍历items中的每一篇笔记\n",
    "for url in URL_list:\n",
    "    whole_url = 'https://www.xiaohongshu.com/discovery/item/' + url# 构造完整笔记URL\n",
    "    browser.get(whole_url)\n",
    "    WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@name=\"description\"]')))# 等待笔记页面加载完成\n",
    "    html = browser.page_source\n",
    "\n",
    "    selector = Selector(text = html)# 解析网页内容\n",
    "    \n",
    "    try:\n",
    "        # 选择并提取网页数据\n",
    "        comment_nr = selector.xpath('//*[@class=\"total\"]/text()').extract_first()# 评论数量\n",
    "        content = selector.xpath('//*[@name=\"description\"]/@content').extract_first()# 内容\n",
    "        datePublished = selector.xpath('//*[@class=\"date\"]/text()').extract_first()# 发布时间\n",
    "        images = selector.xpath('//*[@name=\"og:image\"]/@content').extract_first()# 图片\n",
    "        images = images + '.jpg' if images else None# 追加图片链接\n",
    "        star_nr = selector.xpath('//*[@class=\"count\"]/text()').extract_first()# 收藏数量\n",
    "\n",
    "        commentNr_list.append(comment_nr)\n",
    "        content_list.append(content)\n",
    "        datePublished_list.append(datePublished)\n",
    "        images_list.append(images)\n",
    "        starNr_list.append(star_nr)\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    qbar.update(1)\n",
    "    \n",
    "    wait_time = random.uniform(0.5, 2)\n",
    "    time.sleep(wait_time)\n",
    "\n",
    "qbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(commentNr_list) == len(content_list) == len(datePublished_list) == len(images_list) == len(starNr_list) == num):\n",
    "    print(\"所有属性列表长度均为\", num,\"，爬取成功！\")\n",
    "    print('检查时间:',time.ctime())\n",
    "else:\n",
    "    min_length = min(len(commentNr_list), len(content_list), len(datePublished_list), len(images_list), len(starNr_list))\n",
    "    print(\"当前属性列表长度最小值为\", min_length, \"请重新运行上一代码单元，直至所有属性列表长度均为\", num, \"！\")\n",
    "    print('检查时间:',time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据清洗\n",
    "# 定义函数：使用正则表达式提取所有数字\n",
    "def extract_number(x):\n",
    "    # 检查变量类型\n",
    "    if x is None or not isinstance(x, str):\n",
    "        return None\n",
    "    numbers = re.findall(r'\\d+', x)\n",
    "    if numbers:\n",
    "        return int(numbers[0])# 转换数据\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "commentNr_list = [extract_number(commentNr) for commentNr in commentNr_list]\n",
    "starNr_list = [extract_number(star_nr) for star_nr in starNr_list]\n",
    "\n",
    "# 定义函数：使用正则表达式提取所有日期\n",
    "def extract_date(datePublished):\n",
    "    if datePublished is None or not isinstance(datePublished, str):\n",
    "        return None\n",
    "    else:\n",
    "        match = re.search(r'\\d{4}-\\d{2}-\\d{2}', datePublished)\n",
    "        if match:\n",
    "            return match.group()# 转换数据\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "datePublished_list = [datetime.strptime(extract_date(date), \"%Y-%m-%d\") if extract_date(date) else None for date in datePublished_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"以下为清洁数据示例：\")\n",
    "for i in range(3):\n",
    "    print(\"comment_nr:\", commentNr_list[i])\n",
    "    print(\"content:\", content_list[i])\n",
    "    print(\"datePublished:\", datePublished_list[i])\n",
    "    print(\"images:\", images_list[i])\n",
    "    print(\"star_nr:\", starNr_list[i])\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authorCollectNr_list = []\n",
    "authorFansNr_list = []\n",
    "authorNoteNr_list = []\n",
    "\n",
    "wait_time = random.uniform(1, 2)\n",
    "\n",
    "# 进度条: 实时跟踪已爬取的笔记数量\n",
    "qbar = tqdm(total=len(userURL_list))\n",
    "\n",
    "# 定义循环：遍历items中的每一篇笔记\n",
    "for user_url in userURL_list_cleaned:\n",
    "    whole_url = 'https://www.xiaohongshu.com/user/profile/' + user_url# 构造完整个人页面URL\n",
    "    browser.get(whole_url)\n",
    "\n",
    "    while True:\n",
    "        previous_page_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")# 模拟鼠标滚动到页面底部\n",
    "        time.sleep(wait_time)\n",
    "\n",
    "        current_page_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        # 检查滚动后页面高度变化\n",
    "        if current_page_height == previous_page_height:\n",
    "            break\n",
    "        previous_page_height = current_page_height\n",
    "\n",
    "    WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"userPostedFeeds\"]//section')))# 等待笔记页面加载完成\n",
    "    # 解析完成加载的网页内容\n",
    "    html = browser.page_source\n",
    "    selector = Selector(text=html)\n",
    "    \n",
    "    # 选择并提取网页数据\n",
    "    author_collect_nr = selector.xpath('//*[@class=\"data-info\"]/div[1]/div[3]/span[@class=\"count\"]/text()').extract_first()# 作者获赞与收藏数量\n",
    "    author_fans_nr = selector.xpath('//*[@class=\"data-info\"]/div[1]/div[2]/span[@class=\"count\"]/text()').extract_first()# 作者粉丝数量\n",
    "    author_note_nr = len(selector.xpath('//*[@id=\"userPostedFeeds\"]//section'))# 作者笔记数量\n",
    "\n",
    "    authorCollectNr_list.append(author_collect_nr)\n",
    "    authorFansNr_list.append(author_fans_nr)\n",
    "    authorNoteNr_list.append(author_note_nr)\n",
    "    \n",
    "    qbar.update(1)\n",
    "    time.sleep(wait_time)\n",
    "\n",
    "qbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(authorCollectNr_list) == len(authorFansNr_list) == len(authorNoteNr_list) == num):\n",
    "    print(\"所有属性列表长度均为\", num,\"，爬取成功！\")\n",
    "    print('检查时间:',time.ctime())\n",
    "else:\n",
    "    min_length = min(len(authorCollectNr_list), len(authorFansNr_list), len(authorNoteNr_list))\n",
    "    print(\"当前属性列表长度最小值为\", min_length, \"请重新运行上一代码单元，直至所有属性列表长度均为\", num, \"！\")\n",
    "    print('检查时间:',time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据清洗\n",
    "# 定义函数：使用正则表达式提取所有数字\n",
    "def extract_largeNumber(element):\n",
    "    match = re.search(r'(\\d+(\\.\\d+)?万?)', element)\n",
    "    if match:\n",
    "        number_str = match.group(1)\n",
    "        if '万' in number_str:\n",
    "                number = float(number_str.replace('万', ''))\n",
    "                number = int(number * 10000)\n",
    "        else:\n",
    "            number = int(number_str)\n",
    "        return number\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "authorCollectNr_list_cleaned = [extract_largeNumber(author_collect_nr) for author_collect_nr in authorCollectNr_list]\n",
    "authorFansNr_list_cleaned = [extract_largeNumber(author_fans_nr) for author_fans_nr in authorFansNr_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"以下为清洁数据示例：\")\n",
    "for i in range(3):\n",
    "    print(\"author_collect_nr:\", authorCollectNr_list_cleaned[i])\n",
    "    print(\"author_fans_nr:\", authorFansNr_list_cleaned[i])\n",
    "    print(\"author_note_nr:\", authorNoteNr_list[i])\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = f\"{key_word}{selected_order_text}笔记Top{num}\"\n",
    "\n",
    "# 连接MongoDB\n",
    "myclient=pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb=myclient[\"小红书关键词笔记数据\"]#进行操作的库名\n",
    "mycol=mydb[col_name]#进行操作的集合名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic={\n",
    "    \"author_collect_nr\": authorCollectNr_list_cleaned,# 作者获赞与收藏数量\n",
    "    \"author_fans_nr\": authorFansNr_list_cleaned,# 粉丝数量\n",
    "    \"author_name\": authorName_list,# 作者名字\n",
    "    \"author_note_nr\": authorNoteNr_list,# 作者笔记数量\n",
    "    \"comment_nr\": commentNr_list,# 笔记评论数量\n",
    "    \"content\": content_list,# 笔记内容\n",
    "    \"datePublished\": datePublished_list,# 笔记发布日期\n",
    "    \"images\": images_list,# 笔记封面图片\n",
    "    \"like_nr\": likeNr_list_cleaned,# 笔记获赞数量\n",
    "    \"url\": URL_list,# 笔记URL\n",
    "    \"user_url\": userURL_list_cleaned# 作者URL\n",
    "    }\n",
    "\n",
    "df = pd.DataFrame.from_dict(dic)\n",
    "df = df[~df.duplicated(keep='first')]# 检索并删除所有属性值都相同的行,即保留第一次出现的行，删除后续的重复行\n",
    "print(\"删除\", num-len(df), \"行重复行后剩余\", len(df), \"行。\")\n",
    "print('检查时间:',time.ctime())\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycol.insert_many(df.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myclient.close()# 关闭MongoDB客户端连接"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
