{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入包(PypI)\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scrapy.selector import Selector\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 启动 Chrome 浏览器实例：\n",
    "\n",
    "打开 **cmd** 命令提示符<输入以下命令（将 `your Chrome.exe path` 替换为您的 Chrome 浏览器路径）：\n",
    "```bash\n",
    "& \"your Chrome.exe path\" --remote-debugging-port=9222 --user-data-dir=\"C:\\selenum\\AutomationProfile\"\n",
    "```\n",
    "\n",
    "- 请将your Chrome.exe path替换为您的Chrome浏览器所在路径，例如<br>`C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe`\n",
    "- 配置 chromedriver 相关信息，请参考官方文档：[ChromeDriver](https://developer.chrome.com/docs/chromedriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据清洗可能需要使用的方法\n",
    "def extract_number(List):\n",
    "    list_cleaned = []\n",
    "    for x in List:\n",
    "        if x is None or not isinstance(x, str):\n",
    "            list_cleaned.append(None)\n",
    "            continue\n",
    "        \n",
    "        number = re.findall(r'\\d+\\.?\\d*', x)[0]\n",
    "        if number:\n",
    "            list_cleaned.append(number)\n",
    "        else:\n",
    "            list_cleaned.append(None)\n",
    "    \n",
    "    return list_cleaned\n",
    "\n",
    "def extract_large_number(List):\n",
    "    list_cleaned = []\n",
    "    for x in List:\n",
    "        if x is None or not isinstance(x, str):\n",
    "            list_cleaned.append(None)\n",
    "            continue\n",
    "        \n",
    "        if '万' in x:\n",
    "            number = x.replace('万', '')\n",
    "            number = float(number) * 10000\n",
    "            number = int(number)\n",
    "        else:\n",
    "            number = int(float(x))\n",
    "        \n",
    "        list_cleaned.append(number)\n",
    "        \n",
    "    return list_cleaned\n",
    "\n",
    "def extract_date(List):\n",
    "    list_cleaned = []\n",
    "    for x in List:\n",
    "        match = re.search(r'(\\d{4})-(\\d{2})-(\\d{2})', x)\n",
    "        if match:\n",
    "            date_cleand = match.group(0)\n",
    "        else:\n",
    "            match = re.search(r'(\\d{2})-(\\d{2})', x)\n",
    "            if match:\n",
    "                current_year = datetime.now().year\n",
    "                month, day = match.groups()\n",
    "                date_cleand = f'{current_year}-{month}-{day}'\n",
    "        \n",
    "        list_cleaned.append(date_cleand)\n",
    "    \n",
    "    return list_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置Chrome浏览器\n",
    "service = Service(\"C:\\\\Program Files\\\\Google\\\\Chrome\\\\Application\\\\chromedriver.exe\")\n",
    "\n",
    "options = Options()\n",
    "options.add_experimental_option('debuggerAddress', '127.0.0.1:9222')# 远程调控模式启用\n",
    "options.add_argument('--incognito')# 隐身/无痕模式启用\n",
    "browser = webdriver.Chrome(service=service, options=options)\n",
    "action = ActionChains(browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word = \"\"\n",
    "num = 0\n",
    "\n",
    "def check_login_status(browser):\n",
    "    print(\"即将开始检查小红书登录状态...\")\n",
    "    print(\"爬取数据有账户封禁的风险，建议使用非主账号登录。\")\n",
    "    \n",
    "    while True:\n",
    "        page_source = browser.page_source\n",
    "        if '登录探索更多内容' in page_source:\n",
    "            print('暂未登录，请手动登录')\n",
    "            print('检查时间:', time.ctime())\n",
    "            time.sleep(10)\n",
    "        else:\n",
    "            print('登录成功')\n",
    "            print('检查时间:', time.ctime())\n",
    "            time.sleep(3)\n",
    "            break\n",
    "\n",
    "def check_page_load_status(browser, keyword):\n",
    "    print(\"即将开始检查网页加载状态...\")\n",
    "    print(\"如果网页进入人机验证页面，请先手动完成验证。\")\n",
    "    \n",
    "    while True:\n",
    "        if keyword in browser.title:\n",
    "            print('加载成功')\n",
    "            print('检查时间:', time.ctime())\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(2)\n",
    "\n",
    "def selenium_test():\n",
    "    \"\"\"\n",
    "    登录状态检查，网页加载检查，根据用户输入进行搜索\n",
    "    \"\"\"\n",
    "    global key_word, num\n",
    "    browser.get('https://www.xiaohongshu.com/explore')\n",
    "    \n",
    "    check_login_status(browser)\n",
    "    \n",
    "    print(\"请在文本框中根据提示输入搜索关键词和笔记爬取数量。\")\n",
    "    keyword = input(\"搜索关键词：\")\n",
    "    try:\n",
    "        num = int(input(\"笔记爬取数量：\"))\n",
    "    except ValueError:\n",
    "        print(\"请输入有效的整数作为爬取数量。\")\n",
    "        return\n",
    "    \n",
    "    url = f'https://www.xiaohongshu.com/search_result?keyword={keyword}&source=web_explore_feed'\n",
    "    browser.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    check_page_load_status(browser, keyword)\n",
    "\n",
    "selenium_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_mode(browser):\n",
    "    # 更改模式为图文\n",
    "    try:\n",
    "        mode_button = browser.find_element(By.XPATH, '//*[@id=\"search-type\"]/div/div/div[2]')\n",
    "        mode_button.click()\n",
    "        print('已自动更改模式为图文。')\n",
    "    except Exception as e:\n",
    "        print(f\"更改模式失败: {e}\")\n",
    "\n",
    "selected_order_text = ''\n",
    "def change_sort_order(browser, action):\n",
    "    # 更改排序方式\n",
    "    sort_order = {\n",
    "        '综合': 1,\n",
    "        '最新': 2,\n",
    "        '最热': 3\n",
    "    }\n",
    "    print(\"请选择排序方式:\")\n",
    "    for idx, order in sort_order.items():\n",
    "        print(f'{order}. {idx}')\n",
    "    \n",
    "    try:\n",
    "        global selected_order_text\n",
    "        selected_order_text = input(\"请输入排序方式对应的名称: \").strip()\n",
    "        if selected_order_text not in sort_order:\n",
    "            print(\"请输入有效的排序方式...\")\n",
    "            return\n",
    "        \n",
    "        selected_order_index = sort_order[selected_order_text]\n",
    "    except Exception as e:\n",
    "        print(f\"处理排序选择时出错: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        element = browser.find_element(By.XPATH, '//*[@id=\"global\"]/div[2]/div[2]/div/div[1]/div[2]')\n",
    "        action.move_to_element(element).perform()# 模拟鼠标悬停\n",
    "        menu = browser.find_element(By.CLASS_NAME, 'dropdown-items')\n",
    "        option = menu.find_element(By.XPATH, f'/html/body/div[4]/div/li[{selected_order_index}]')\n",
    "        option.click()# 模拟鼠标点击\n",
    "\n",
    "        print('已选择排序方式为:',selected_order_text)\n",
    "        print('检查时间:',time.ctime())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"更改排序方式失败: {e}\")\n",
    "\n",
    "change_mode(browser)\n",
    "change_sort_order(browser, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsePage(html_content, authorName_list, likeNr_list, URL_list, userURL_list, num):\n",
    "    \"\"\"\n",
    "    解析网页内容并更新数据列表。\n",
    "\n",
    "    Args:\n",
    "        html_content (str): 当前页面的HTML内容\n",
    "        authorName_list (list): 存储作者名字的列表\n",
    "        likeNr_list (list): 存储获赞数量的列表\n",
    "        URL_list (list): 存储笔记URL的列表\n",
    "        userURL_list (list): 存储用户URL的列表\n",
    "        qbar (tqdm): 进度条对象\n",
    "        num (int): 需要爬取的笔记数量\n",
    "\n",
    "    Returns:\n",
    "        None: 数据存储在传入的列表中\n",
    "    \"\"\"\n",
    "    response = Selector(text=html_content)\n",
    "    divs = response.xpath('//div[contains(@class, \"feeds-container\")]/section/div')# 选中网页中包含笔记信息的部分\n",
    "\n",
    "    # 遍历divs获取每一篇笔记的信息\n",
    "    for div in divs:\n",
    "        if len(URL_list) >= num:\n",
    "            break\n",
    "        \n",
    "        if div.xpath('.//span[contains(text(), \"大家都在搜\")]'):\n",
    "            continue\n",
    "\n",
    "        # 选择并提取网页数据\n",
    "        try:\n",
    "            author_name = div.xpath('.//a[contains(@class, \"author\")]/span[contains(@class, \"name\")]/text()').get()# 作者名字\n",
    "            like_nr = div.xpath('.//span[contains(@class, \"count\")]/text()').get()# 获赞数量\n",
    "            url = div.xpath('.//a[contains(@class, \"cover\")]/@href').get()# 笔记URL\n",
    "            user_url = div.xpath('.//a[contains(@class, \"author\")]/@href').get()# 用户URL\n",
    "            \n",
    "            authorName_list.append(author_name)\n",
    "            likeNr_list.append(like_nr)\n",
    "            URL_list.append(url)\n",
    "            userURL_list.append(user_url)\n",
    "\n",
    "            time.sleep(0.35)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return True\n",
    "\n",
    "authorName_list, likeNr_list, URL_list, userURL_list = [], [], [], []\n",
    "qbar = tqdm(total=num, desc=\"已获取的笔记数量...\")\n",
    "\n",
    "# 检查是否已经爬取足够数量的笔记，或是否已经达到页面底部\n",
    "while len(URL_list) < num:\n",
    "    if '- THE END -' in browser.page_source:\n",
    "        print(f\"当前与{key_word}有关的笔记数量少于 {num}\")\n",
    "        print('检查时间:',time.ctime())\n",
    "        break\n",
    "    \n",
    "    parsePage(browser.page_source, authorName_list, likeNr_list, URL_list, userURL_list, num)\n",
    "    qbar.update(1)\n",
    "\n",
    "    if len(URL_list) < num:\n",
    "        browser.execute_script('window.scrollTo(0,document.body.scrollHeight)')# 模拟鼠标滚动\n",
    "        time.sleep(random.uniform(3, 5))\n",
    "\n",
    "if len(URL_list) > num:\n",
    "    URL_list = URL_list[:num]\n",
    "    authorName_list = authorName_list[:num]\n",
    "    likeNr_list = likeNr_list[:num]\n",
    "    userURL_list = userURL_list[:num]\n",
    "\n",
    "qbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(len(lst) == num for lst in [authorName_list, likeNr_list, URL_list, userURL_list]):\n",
    "    print(f\"所有属性列表长度均为 {num}，爬取成功！\")\n",
    "    print(f'检查时间: {time.ctime()}')\n",
    "else:\n",
    "    min_length = min(map(len, [authorName_list, likeNr_list, URL_list, userURL_list]))\n",
    "    print(f\"当前属性列表长度最小值为 {min_length}，请重新运行上一代码单元，直至所有属性列表长度均为 {num}！\")\n",
    "    print(f'检查时间: {time.ctime()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likeNr_list = extract_large_number(likeNr_list)\n",
    "URL_list = [re.sub(r'^/search_result/', '/', url) for url in URL_list]\n",
    "userURL_list = [url.split('/')[-1] for url in userURL_list]\n",
    "\n",
    "print(\"以下为清洁数据示例:\\n\")\n",
    "for i in range(3):\n",
    "    print(\"author_name:\", authorName_list[i])\n",
    "    print(\"like_nr:\", likeNr_list[i])\n",
    "    print(\"url:\", URL_list[i])\n",
    "    print(\"user_url:\", userURL_list[i])\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_note_page(browser, url, commentNr_list, content_list, datePublished_list, images_list, starNr_list):\n",
    "    \"\"\"\n",
    "    解析单个笔记页面并提取所需数据\n",
    "    \n",
    "    Args:\n",
    "        browser: Selenium WebDriver 实例，用于获取页面内容\n",
    "        url: 笔记的URL\n",
    "        commentNr_list (list): 存储评论数量的列表\n",
    "        content_list (list): 存储笔记内容的列表\n",
    "        datePublished_list (list): 存储发布时间的列表\n",
    "        images_list (list): 存储图片链接的列表\n",
    "        starNr_list (list): 存储收藏数量的列表\n",
    "\n",
    "    Returns:\n",
    "        None: 将提取的数据添加到相应的列表中\n",
    "    \"\"\"\n",
    "    whole_url = 'https://www.xiaohongshu.com/explore' + url# 构造完整笔记URL\n",
    "    browser.get(whole_url)\n",
    "    WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@name=\"description\"]')))# 等待页面加载完成\n",
    "    html = browser.page_source\n",
    "    selector = Selector(text = html)\n",
    "    \n",
    "    try:\n",
    "        # 选择并提取网页数据\n",
    "        comment_nr = selector.xpath('//*[@class=\"total\"]/text()').extract_first()# 评论数量\n",
    "        content = selector.xpath('//*[@name=\"description\"]/@content').extract_first()# 内容\n",
    "        datePublished = selector.xpath('//*[@class=\"date\"]/text()').extract_first()# 发布时间\n",
    "        images = selector.xpath('//*[@name=\"og:image\"]/@content').extract_first()# 图片\n",
    "        images = images + '.jpg' if images else None# 追加图片链接\n",
    "        star_nr = selector.xpath('//*[@class=\"count\"]/text()').extract_first()# 收藏数量\n",
    "\n",
    "        commentNr_list.append(comment_nr)\n",
    "        content_list.append(content)\n",
    "        datePublished_list.append(datePublished)\n",
    "        images_list.append(images)\n",
    "        starNr_list.append(star_nr)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "commentNr_list, content_list, datePublished_list, images_list, starNr_list = [], [], [], [], []\n",
    "\n",
    "qbar = tqdm(total=len(URL_list), desc=\"已获取的笔记数量...\")\n",
    "for url in URL_list:\n",
    "    parse_note_page(browser, url, commentNr_list, content_list, datePublished_list, images_list, starNr_list)\n",
    "    qbar.update(1)\n",
    "    time.sleep(random.uniform(0.5, 2))\n",
    "\n",
    "qbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(len(lst) == num for lst in [commentNr_list, content_list, datePublished_list, images_list, starNr_list]):\n",
    "    print(f\"所有属性列表长度均为 {num}，爬取成功！\")\n",
    "    print(f'检查时间: {time.ctime()}')\n",
    "else:\n",
    "    min_length = min(map(len, [commentNr_list, content_list, datePublished_list, images_list, starNr_list]))\n",
    "    print(f\"当前属性列表长度最小值为 {min_length}，请重新运行上一代码单元，直至所有属性列表长度均为 {num}！\")\n",
    "    print(f'检查时间: {time.ctime()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentNr_list = extract_large_number(extract_number(commentNr_list))\n",
    "starNr_list = extract_large_number(starNr_list)\n",
    "datePublished_list = extract_date(datePublished_list)\n",
    "\n",
    "print(\"以下为清洁数据示例:\\n\")\n",
    "for i in range(3):\n",
    "    print(\"comment_nr:\", commentNr_list[i])\n",
    "    print(\"content:\", content_list[i])\n",
    "    print(\"datePublished:\", datePublished_list[i])\n",
    "    print(\"images:\", images_list[i])\n",
    "    print(\"star_nr:\", starNr_list[i])\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_author_page(browser, user_url, authorCollectNr_list, authorFansNr_list, authorNoteNr_list):\n",
    "    \"\"\"\n",
    "    解析单个用户页面并提取所需数据\n",
    "    \n",
    "    Args:\n",
    "        browser: Selenium WebDriver 实例，用于获取页面内容\n",
    "        user_url: 用户的URL\n",
    "        authorCollectNr_list (list): 存储作者获赞与收藏数量的列表\n",
    "        authorFansNr_list (list): 存储作者粉丝数量的列表\n",
    "        authorNoteNr_list (list): 存储作者笔记数量的列表\n",
    "    \n",
    "    Returns:\n",
    "        None: 将提取的数据添加到相应的列表中\n",
    "    \"\"\"\n",
    "    whole_url = 'https://www.xiaohongshu.com/user/profile/' + user_url# 构造完整用户页面URL\n",
    "    browser.get(whole_url)\n",
    "\n",
    "    # 模拟滚动页面直到加载完成\n",
    "    while True:\n",
    "        previous_page_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")# 滚动到页面底部\n",
    "        time.sleep(random.uniform(1, 2))\n",
    "\n",
    "        current_page_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        if current_page_height == previous_page_height:\n",
    "            break\n",
    "        previous_page_height = current_page_height\n",
    "\n",
    "    WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"userPostedFeeds\"]//section')))# 等待页面加载完成\n",
    "    html = browser.page_source\n",
    "    selector = Selector(text=html)\n",
    "\n",
    "    try:\n",
    "        # 选择并提取网页数据\n",
    "        author_collect_nr = selector.xpath('//*[@class=\"data-info\"]/div[1]/div[3]/span[@class=\"count\"]/text()').extract_first()# 作者获赞与收藏数量\n",
    "        author_fans_nr = selector.xpath('//*[@class=\"data-info\"]/div[1]/div[2]/span[@class=\"count\"]/text()').extract_first()# 作者粉丝数量\n",
    "        author_note_nr = len(selector.xpath('//*[@id=\"userPostedFeeds\"]//section'))# 作者笔记数量\n",
    "\n",
    "        authorCollectNr_list.append(author_collect_nr)\n",
    "        authorFansNr_list.append(author_fans_nr)\n",
    "        authorNoteNr_list.append(author_note_nr)\n",
    "\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "authorCollectNr_list, authorFansNr_list, authorNoteNr_list = [], [], []\n",
    "\n",
    "qbar = tqdm(total=len(userURL_list), desc=\"已爬取的作者数量...\")\n",
    "for user_url in userURL_list:\n",
    "    parse_author_page(browser, user_url, authorCollectNr_list, authorFansNr_list, authorNoteNr_list)\n",
    "    qbar.update(1)\n",
    "    time.sleep(random.uniform(1, 2))\n",
    "\n",
    "qbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(len(lst) == num for lst in [authorCollectNr_list, authorFansNr_list, authorNoteNr_list]):\n",
    "    print(f\"所有属性列表长度均为 {num}，爬取成功！\")\n",
    "    print(f'检查时间: {time.ctime()}')\n",
    "else:\n",
    "    min_length = min(map(len, [authorCollectNr_list, authorFansNr_list, authorNoteNr_list]))\n",
    "    print(f\"当前属性列表长度最小值为 {min_length}，请重新运行上一代码单元，直至所有属性列表长度均为 {num}！\")\n",
    "    print(f'检查时间: {time.ctime()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authorCollectNr_list = extract_large_number(authorCollectNr_list)\n",
    "authorFansNr_list = extract_large_number(authorFansNr_list)\n",
    "\n",
    "print(\"以下为清洁数据示例：\")\n",
    "for i in range(3):\n",
    "    print(\"author_collect_nr:\", authorCollectNr_list[i])\n",
    "    print(\"author_fans_nr:\", authorFansNr_list[i])\n",
    "    print(\"author_note_nr:\", authorNoteNr_list[i])\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic={\n",
    "    \"author_collect_nr\": authorCollectNr_list,# 作者获赞与收藏数量\n",
    "    \"author_fans_nr\": authorFansNr_list,# 粉丝数量\n",
    "    \"author_name\": authorName_list,# 作者名字\n",
    "    \"author_note_nr\": authorNoteNr_list,# 作者笔记数量\n",
    "    \"comment_nr\": commentNr_list,# 笔记评论数量\n",
    "    \"content\": content_list,# 笔记内容\n",
    "    \"datePublished\": datePublished_list,# 笔记发布日期\n",
    "    \"images\": images_list,# 笔记封面图片\n",
    "    \"like_nr\": likeNr_list,# 笔记获赞数量\n",
    "    \"url\": URL_list,# 笔记URL\n",
    "    \"user_url\": userURL_list# 作者URL\n",
    "    }\n",
    "\n",
    "df = pd.DataFrame.from_dict(dic)\n",
    "df = df[~df.duplicated(keep='first')]# 检索并删除所有属性值都相同的行,即保留第一次出现的行，删除后续的重复行\n",
    "print(\"删除\", num-len(df), \"行重复行后剩余\", len(df), \"行。\")\n",
    "print('检查时间:',time.ctime())\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = f\"{key_word}{selected_order_text}笔记Top{num}\"\n",
    "\n",
    "# 连接MongoDB\n",
    "myclient=pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb=myclient[\"小红书关键词笔记数据\"]#进行操作的库名\n",
    "mycol=mydb[col_name]#进行操作的集合名\n",
    "\n",
    "mycol.insert_many(df.to_dict('records'))\n",
    "\n",
    "myclient.close()# 关闭MongoDB客户端连接\n",
    "browser.close()# 关闭Chrome"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
